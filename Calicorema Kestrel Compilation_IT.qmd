---
title: "Kestrel compilation for Calicorema"
author: "Heather Throop"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

# Overview

This script reads in csv files from individual Kestrel loggers, merges the files, and synthesizes the data.

This was created for the Calicorema group during the 2023 IRES at Gobabeb.

Created July 27, 2023 Heather Throop\
\
To run this code, all raw Kestrel files are located in dropbox and can be ran from any desktop.

Make sure you have the following packages installed:

```{r}
#| label: load-packages
library(here) # v. 0.1
library(stringr) # v. 1.2.0
library(purrr) # v. 0.2.3
library(tidyverse)
library(scales)
library(readr)
```

# Read and Clean Data

### List Kestrel Files

Note that the "more columns than column names" error is likely to happen. Find the offending file (use the last line of code in this chunk to do so) and delete extra columns to the right of the data.\
\
Much of this code is based on the commentary from: https://aosmith.rbind.io/2017/12/31/many-datasets/ . You can read further details on this approach there.

#Listing all Kestrel csv files (located in DropBox) in a vector for easier read in and formatting from "1" to "0". There are nine total csv files for the nine kestrels that were deployed for the IRES CACA relative humidity and temperature data collection.

```{r}
#|label: Dropbox links into a vector for easier download formatting
#insert all dropbox links into a vector:
links<- c(
  "https://www.dropbox.com/scl/fi/uw29315xatnz935nsbdug/D2_-_2605751_Jul_29_2023_10_40_00-2.csv?rlkey=hjfm1s854tlrxft5jsqnn0hmw&st=keyqd29c&dl=0",
  "https://www.dropbox.com/scl/fi/7qst9hymdteeqs9nyebx1/D2_-_2605746_Jul_29_2023_11_00_00-2.csv?rlkey=ngbieskuw45cga5qsctmdg6g3&st=eb4y5lhd&dl=0",
  "https://www.dropbox.com/scl/fi/3huclmmg31xmnmv0j4fi7/D2_-_2593669_Jul_29_2023_11_00_00-2.csv?rlkey=kmdlfnuxyq3l6c5zkv5cen8to&st=l4w4opyf&dl=0",
  "https://www.dropbox.com/scl/fi/s85z842lswxgwoxa213xw/D2_-_2593668_Jul_29_2023_10_40_00-2.csv?rlkey=i0anqzalypamj0uqvek0use0n&st=3cmlbw7m&dl=0",
  "https://www.dropbox.com/scl/fi/lbcob93wu4htboqndn55p/D2_-_2593667_Jul_29_2023_10_40_00-2.csv?rlkey=3vvxgjvgv4bqac0hccnhoxjuh&st=6pkqqkpk&dl=0",
  "https://www.dropbox.com/scl/fi/u240ikws6ccmawpesb9y7/D2_-_2593666_Jul_29_2023_11_20_00.csv?rlkey=i0snv6b9wmz70z6d2nt65st2v&st=ngxujdax&dl=0",
  "https://www.dropbox.com/scl/fi/zqlrnbdz5kvac41i34xx7/D2_-_2593626_Jul_29_2023_10_40_00-2.csv?rlkey=hpne55csbvsiy44ksu0mx01du&st=ub96bnnj&dl=0",
  "https://www.dropbox.com/scl/fi/bwi1f7nr40ubx8ctcmyfe/D2_-_2593624_Jul_29_2023_11_00_00-2.csv?rlkey=h9jxr1h7y9gtdhcoitmgiof9z&st=3acehe86&dl=0",
  "https://www.dropbox.com/scl/fi/qk19sh6rp93zdyuwgxgm5/D2_-_2592691_Jul_29_2023_10_40_00-2.csv?rlkey=gat5cavgfd2q94ree2nqwvkej&st=g6523aqw&dl=0"
)

##convert to a direct download by changing "dl=0" to "dl=1"
direct_links<- sub("dl=0", "dl=1", links, fixed = TRUE)
#load all of them 

data_list <- lapply(direct_links, function(u) {
  read_csv(
    u,
    skip = 5,              #skip the metadata rows (Device Name, Device Model...)
    show_col_types = FALSE
  )
})




#remove rows with NA's after data blocks
data_list_clean <- lapply(data_list, function(df) {
  df %>% 
    # keep only the first 6 columns (up to Data Type)
    select(1:6) %>% 
    # keep rows where the timestamp is not NA (drops any empty rows)
    filter(!is.na(`yyyy-MM-dd hh:mm:ss a`))
})

```

```{r}
# 1. Rename columns & drop Data Type
# 1. Rename columns & drop Data Type
data_list_clean <- lapply(data_list_clean, function(df) {
  df %>%
    rename(
      datetime       = `yyyy-MM-dd hh:mm:ss a`,
      temp_c         = `°C...2`,
      rel_humidity   = `%`,
      heat_index_c   = `°C...4`,
      dew_point_c    = `°C...5`,
      data_type      = `Data Type`
    ) %>%
    select(-data_type)   # drop if it's always "point"
})

# extract filenames from direct links
filenames <- basename(sub("\\?.*$", "", direct_links))

# extract logger ID (7-digit number)
logger_ids <- str_extract(filenames, "\\d{7}")

# name each logger’s dataset
names(data_list_clean) <- logger_ids

# combine into one dataset with logger_id column
combined <- bind_rows(data_list_clean, .id = "logger_id")





```

#GRAVEYARD: HT code from here down....
```{r}


# reading and extract loggerID
read_fun = function(path) {
  test = read.csv(path, 
                  skip = 5,
                  header = FALSE,
                  col.names = c("datetime", "temperature", "RH", "heatindex", "dewpoint", "datatype") )
  allnames = str_split( path, pattern = "/", simplify = TRUE)
 test$loggerID = str_extract(allnames[, ncol(allnames)], pattern = "2[0-9][0-9][0-9][0-9][0-9][0-9]") #extract the loggerID from the file name and add as a column
  test$RH <- as.numeric(as.character(test$RH))
  test$heatindex <- as.numeric(as.character(test$heatindex))
  test$dewpoint <- as.numeric(as.character(test$dewpoint))
  test$temperature <- as.numeric(as.character(test$temperature))
  test$loggerID <- as.numeric(as.character(test$loggerID))
  test
}

# Line below is useful for testing if logger name is being assigned
# change the number in brackets to check show the top section of each file
read_fun(allfiles[1]) # use to test the function on an individual file

```

### Read in and Combine Files

```{r}
#| label: combine-kestrel-files
combined_kestrel_notcleaned = map_dfr(allfiles, read_fun) # combine all the files
combined_kestrel_notcleaned$loggertype <- "Kestrel" #add a column for the kind of logger used (Kestrel in this case)

# check that we have the right number of loggers in the file
combined_kestrel_notcleaned |>
  group_by(loggerID) |> 
  summarize(n = n())

# Add in microsite and block information
df_loggers <- read.csv("Kestrel_IDs.csv", header = TRUE)
df_loggers$loggerID <- as.numeric(df_loggers$loggerID)
combined_kestrel_notcleaned <- combined_kestrel_notcleaned |>
  left_join(df_loggers, join_by(loggerID))

```

### Time formatting

Check that the time column is populated *for all loggers*. If not, the format might be incorrect - sometimes Kestels are set to send the datetime output in different formats. This code attempts to bet-hedge by re-formatting from two of the most common datetime formats.

```{r}
#| label: Fix-datetime-formatting 

# the Kestels may have two (or more) different date/time formats - do one set here
combined_kestrel_notcleaned_a <- combined_kestrel_notcleaned # make duplicate df 
combined_kestrel_notcleaned_a$time <- strptime(combined_kestrel_notcleaned_a$datetime, format = "%Y-%m-%d %H:%M:%S", tz = "Africa/Johannesburg") # convert date and time into a time object
combined_kestrel_notcleaned_a <- combined_kestrel_notcleaned_a[!(is.na(combined_kestrel_notcleaned_a$time)), ]

# convert the remainning another set here
combined_kestrel_notcleaned_b <- combined_kestrel_notcleaned # make duplicate df 
combined_kestrel_notcleaned_b$time <- strptime(combined_kestrel_notcleaned_b$datetime, format = "%m/%d/%y %H:%M", tz = "Africa/Johannesburg") # convert date and time into a time object
combined_kestrel_notcleaned_b <- combined_kestrel_notcleaned_b[!(is.na(combined_kestrel_notcleaned_b$time)), ]

# now merge the two dfs - this should bring us back to the original number of observations, all of which should have a datetime in the new "time" column
combined_kestrel_notcleaned <- rbind(combined_kestrel_notcleaned_a, combined_kestrel_notcleaned_b) 

combined_kestrel_notcleaned$time <- as.POSIXct(combined_kestrel_notcleaned$time) # parses date into the POSIXct format 

# remove any data before the deployment date
# NOTE THAT THE DATE MAY NEED TO BE ADJUSTED - PLACE THE DESIRED START DATE BELOW
L2_kestrel_data <-combined_kestrel_notcleaned[combined_kestrel_notcleaned[["time"]] >= "2021-07-04", ]  

#save the output as a .csv file
write.csv(L2_kestrel_data, "combined_kestrel_notcleaned.csv") 

# check the data carefully to see if any additional cleaning is needed!
```

Note: Before moving on to the next step, it is important to check the data to make sure that no additional cleaning is needed.

# Individual Logger Plots

Below are separate plots for each logger (grouped by treatment). These are intended to check the data (e.g., gaps in logs for different loggers and correct number of loggers per site).

## RH

note - probably you'll want to play around with scale_x_datetime to give yourself some appropriate x axis scales.

```{r}
#| label: RH-plot

L2_kestrel_data |>
  ggplot(aes(x=time, y=RH, color = Treatment, group = 1)) + 
    labs(title = " ") +
    geom_line() +
    xlab(" ") +
    ylab("RH (%)") +
    scale_x_datetime(date_breaks = "4 hour", labels = date_format("%m%d %H%m")) +
    facet_grid(loggerID ~ .) 

```

## Temperature

```{r}

L2_kestrel_data |>
  ggplot(aes(x=time, y=temperature, color = Treatment, group = 1)) + 
    labs(title = " ") +
    geom_line() +
    xlab(" ") +
    ylab("Temperature (C)") +
    scale_x_datetime(date_breaks = "4 hour", labels = date_format("%m%d %H%m")) +
    facet_grid(loggerID ~ .) 

```

# Treatment Means

*Check that the tibble output after running this chunk looks reasonable. N should equal the expected number of loggers. There should be values for SD and SE, assuming that there is more than one logger for each time point.*

```{r}
#| label: hourly-treatment-means
# create df that condenses the multiple loggers per Treatment down to one mean value per hour

Kestrel_hourlymeans_df <- L2_kestrel_data |>
  group_by(Treatment, time) |>
  summarize(
               N    = sum(!is.na(RH)),
               mean_T = mean(temperature, na.rm=TRUE),
               sd_T   = sd(temperature, na.rm=TRUE),
               se_T   = sd_T / sqrt(N),
               mean_RH = mean(RH, na.rm=TRUE),
               sd_RH   = sd(RH, na.rm=TRUE),
               se_RH   = sd_RH / sqrt(N)
               )
Kestrel_hourlymeans_df

```

## Plots of hourly means

### RH

```{r}
#| label: RH-by-treatment

# plots of hourly means by treatment - RH
ggplot(Kestrel_hourlymeans_df, aes(x=time, y=mean_RH, color = Treatment, group = 1)) + 
  geom_point() +
  theme_bw() +
  ylab("Relative Humidity (%)") +
  xlab("") 
 # scale_x_date(limits = as.Date(c("2021-03-01", "2022-11-01")))

```

### Temperature

```{r}
#| label: temperature-by-treatment

# plots of hourly means by treatment - temperature
ggplot(Kestrel_hourlymeans_df, aes(x=time, y=mean_T, color = Treatment, group = 1)) + 
  geom_point() +
  theme_bw() +
  ylab("Temperature (C)") +
  xlab("") 
 # scale_x_date(limits = as.Date(c("2021-03-01", "2022-11-01")))
```
